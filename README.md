# Scuba

Dive in your DataLake.

You can list and create your DataSet on a Hadoop cluster using Apache Hive.

* PublicDataSet : an existing Hive table
* WrangleDataSet : create your Hive table using wrangling tool
* CustomFileDataSet : upload your file (csv, excel file, etc.) as a new Hive table
* CustomSQLQueryDataSet : build your Hive table based on your custom SQL query

Based on an existing DataSet, create cubes

You can register and share queries :
* SQLQuery : a Hive query
* PySparkQuery : a PySpark query



